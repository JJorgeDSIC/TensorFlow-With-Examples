{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation & Model's definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../DATASETS/MNIST_TF/train-images-idx3-ubyte.gz\n",
      "Extracting ../DATASETS/MNIST_TF/train-labels-idx1-ubyte.gz\n",
      "Extracting ../DATASETS/MNIST_TF/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../DATASETS/MNIST_TF/t10k-labels-idx1-ubyte.gz\n",
      "# samples 55000\n",
      "Input's dimension 784\n",
      "Label's dimension 10\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# COMMENTS TO DO\n",
    "#\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "def plot(samples, w, h, fw, fh, iw=28, ih=28):\n",
    "    fig = plt.figure(figsize=(fw, fh))\n",
    "    gs = gridspec.GridSpec(w, h)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(iw, ih), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "DATA_PATH = \"../DATASETS/\"\n",
    "mnist = input_data.read_data_sets(DATA_PATH + \"MNIST_TF/\", one_hot=True)\n",
    "\n",
    "\n",
    "X_TOTAL = mnist.train.images.shape[0]\n",
    "X_DIM = mnist.train.images.shape[1]\n",
    "Y_DIM = mnist.train.labels.shape[1]\n",
    "print(\"# samples {}\".format(X_TOTAL))\n",
    "print(\"Input's dimension {}\".format(X_DIM))\n",
    "print(\"Label's dimension {}\".format(Y_DIM))\n",
    "\n",
    "#Determining data's input (Setting to None first dimension allows us to use a variable batch size)\n",
    "images_placeholder = tf.placeholder(tf.float32, shape=(None, X_DIM))\n",
    "labels_placeholder = tf.placeholder(tf.int32, shape=(None, Y_DIM))\n",
    "learning_rate_placeholder = tf.placeholder(tf.float32)\n",
    "is_training_placeholder = tf.placeholder(tf.bool)\n",
    "\n",
    "#Defining a model\n",
    "def model_batch_norm(images, is_training=True):\n",
    "    \n",
    "    h1 =layers.fully_connected(\n",
    "            inputs=images,\n",
    "            num_outputs=1024,\n",
    "            activation_fn=tf.nn.relu,\n",
    "            normalizer_fn=layers.batch_norm,\n",
    "            normalizer_params={\"is_training\": is_training, \"updates_collections\": None},\n",
    "            scope='d_%d' % (0,)\n",
    "        )\n",
    "\n",
    "    h2 =layers.fully_connected(\n",
    "            inputs=h1,\n",
    "            num_outputs=1024,\n",
    "            activation_fn=tf.nn.relu,\n",
    "            normalizer_fn=layers.batch_norm,\n",
    "            normalizer_params={\"is_training\": is_training, \"updates_collections\": None},\n",
    "            scope='d_%d' % (1,)\n",
    "        )\n",
    "\n",
    "\n",
    "    h3 =layers.fully_connected(\n",
    "            inputs=h2,\n",
    "            num_outputs=1024,\n",
    "            activation_fn=tf.nn.relu,\n",
    "            normalizer_fn=layers.batch_norm,\n",
    "            normalizer_params={\"is_training\": is_training, \"updates_collections\": None},\n",
    "            scope='d_%d' % (2,)\n",
    "        )\n",
    "\n",
    "\n",
    "    logits =layers.fully_connected(\n",
    "            inputs=h3,\n",
    "            num_outputs=10,\n",
    "            activation_fn=None,\n",
    "            normalizer_fn=None,\n",
    "            normalizer_params={\"is_training\": is_training, \"updates_collections\": None},\n",
    "            scope='d_%d' % (3,)\n",
    "        )\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n",
    "output_logits=model_batch_norm(images_placeholder, is_training_placeholder)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=labels_placeholder, logits=output_logits))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate_placeholder).minimize(cross_entropy)\n",
    "\n",
    "#Obtaining accuracy\n",
    "y_pred = tf.argmax(input=output_logits, axis=1)\n",
    "y_true = tf.argmax(input=labels_placeholder, axis=1)\n",
    "\n",
    "correct_prediction = tf.equal(y_pred, y_true)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB INDEX 0\n",
      "MB INDEX 500\n",
      "E 0 | TRAINING ACC: 0.9239 | TIME 39.94 secs\n",
      "859\n",
      "0.923912252619\n",
      "MB INDEX 0\n",
      "MB INDEX 500\n",
      "E 1 | TRAINING ACC: 0.9713 | TIME 38.98 secs\n",
      "859\n",
      "0.971278376019\n",
      "MB INDEX 0\n",
      "MB INDEX 500\n",
      "E 2 | TRAINING ACC: 0.9842 | TIME 37.06 secs\n",
      "859\n",
      "0.9842112922\n",
      "MB INDEX 0\n",
      "MB INDEX 500\n",
      "E 3 | TRAINING ACC: 0.9905 | TIME 44.30 secs\n",
      "859\n",
      "0.990450378347\n",
      "MB INDEX 0\n",
      "MB INDEX 500\n",
      "E 4 | TRAINING ACC: 0.9951 | TIME 43.72 secs\n",
      "859\n",
      "0.995143335274\n",
      "MB INDEX 0\n",
      "MB INDEX 500\n",
      "E 5 | TRAINING ACC: 0.9975 | TIME 43.60 secs\n",
      "859\n",
      "0.997453434226\n",
      "MB INDEX 0\n",
      "MB INDEX 500\n",
      "E 6 | TRAINING ACC: 0.9964 | TIME 39.57 secs\n",
      "859\n",
      "0.996434807916\n",
      "MB INDEX 0\n",
      "MB INDEX 500\n",
      "E 7 | TRAINING ACC: 0.9967 | TIME 35.83 secs\n",
      "859\n",
      "0.996671274738\n",
      "MB INDEX 0\n",
      "MB INDEX 500\n",
      "E 8 | TRAINING ACC: 0.9992 | TIME 39.23 secs\n",
      "859\n",
      "0.999163271246\n",
      "MB INDEX 0\n",
      "MB INDEX 500\n",
      "E 9 | TRAINING ACC: 0.9999 | TIME 36.98 secs\n",
      "859\n",
      "0.999909051222\n",
      "Optimization Finished!\n",
      "Model saved in file: MODELS/MLP_1024_RELU_x3_10_SOFT_BATCH_NORM.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "TOTAL_BATCHES = int(X_TOTAL/BATCH_SIZE)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Models' managing\n",
    "MODELS_PATH = \"MODELS/\"\n",
    "\n",
    "if not os.path.exists(MODELS_PATH):\n",
    "    os.makedirs(MODELS_PATH)\n",
    "\n",
    "MODEL_NAME = \"MLP_1024_RELU_x3_10_SOFT_BATCH_NORM.ckpt\"\n",
    "\n",
    "# 'Saver' op to save and restore all the variables\n",
    "MLP_SAVER = tf.train.Saver()\n",
    "\n",
    "#A Session with a \"with\" block. The Session closes automatically at the end of the with block.\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        batch_indexes = np.random.permutation(TOTAL_BATCHES)\n",
    "        \n",
    "        training_total_acc = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for minibatch_number, batch_index in enumerate(batch_indexes):\n",
    "            \n",
    "            \n",
    "            \n",
    "            X_minibatch = mnist.train.images[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE]\n",
    "            Y_minibatch = mnist.train.labels[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE]\n",
    "\n",
    "            _, minibatch_acc = sess.run([train_step, accuracy], \n",
    "                              feed_dict={\n",
    "                                  images_placeholder: X_minibatch,\n",
    "                                  labels_placeholder: Y_minibatch,\n",
    "                                  learning_rate_placeholder: LEARNING_RATE,\n",
    "                                  is_training_placeholder: True\n",
    "                              })\n",
    "            \n",
    "            training_total_acc+=minibatch_acc\n",
    "            \n",
    "            if minibatch_number % 500 == 0:\n",
    "                print(\"MB INDEX {}\".format(minibatch_number))\n",
    "            \n",
    "        print(\"E {} | TRAINING ACC: {:.4f} | TIME {:.2f} secs\".format(epoch, (training_total_acc * 1.0)/TOTAL_BATCHES, time.time() - start_time))\n",
    "    \n",
    "    print(\"Optimization Finished!\")\n",
    "    #Saving the model\n",
    "    \n",
    "    # Save model weights to disk\n",
    "    save_path = MLP_SAVER.save(sess, MODELS_PATH + MODEL_NAME)\n",
    "    print(\"Model saved in file: {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored in file: MODELS/MLP_1024_RELU_x3_10_SOFT_BATCH_NORM.ckpt\n",
      "MB INDEX 0\n",
      "MB INDEX 10\n",
      "MB INDEX 20\n",
      "MB INDEX 30\n",
      "MB INDEX 40\n",
      "MB INDEX 50\n",
      "MB INDEX 60\n",
      "MB INDEX 70\n",
      "MB INDEX 80\n",
      "MB INDEX 90\n",
      "TEST ACC: 0.9845 | TIME 2.47 secs\n"
     ]
    }
   ],
   "source": [
    "X_TEST_TOTAL = mnist.test.images.shape[0]\n",
    "TEST_BATCH_SIZE = 100\n",
    "TEST_TOTAL_BATCHES = int(X_TEST_TOTAL/TEST_BATCH_SIZE)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    MLP_SAVER.restore(sess, save_path)\n",
    "    print(\"Model restored in file: {}\".format(save_path))\n",
    "    test_total_acc = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for test_minibatch_number in range(TEST_TOTAL_BATCHES):\n",
    "\n",
    "        X_minibatch = mnist.test.images[test_minibatch_number*TEST_BATCH_SIZE:(test_minibatch_number+1)*TEST_BATCH_SIZE]\n",
    "        Y_minibatch = mnist.test.labels[test_minibatch_number*TEST_BATCH_SIZE:(test_minibatch_number+1)*TEST_BATCH_SIZE]\n",
    "\n",
    "        minibatch_acc = sess.run(accuracy, \n",
    "                          feed_dict={\n",
    "                              images_placeholder: X_minibatch,\n",
    "                              labels_placeholder: Y_minibatch,\n",
    "                              is_training_placeholder: False\n",
    "                          })\n",
    "\n",
    "        test_total_acc+=minibatch_acc\n",
    "        \n",
    "        if test_minibatch_number % 10 == 0:\n",
    "            print(\"MB INDEX {}\".format(test_minibatch_number))\n",
    "\n",
    "    print(\"TEST ACC: {:.4f} | TIME {:.2f} secs\".format((test_total_acc * 1.0)/TEST_TOTAL_BATCHES, time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
